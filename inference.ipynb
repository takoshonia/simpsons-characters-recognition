{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The \"Springfield\" Identity - Inference Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "WORK_DIR = '/content/drive/MyDrive/shared/bonusHW'\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpsonsCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpsonsCNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(512 * 4 * 4, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.pool(self.relu(self.bn5(self.conv5(x))))\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.dropout(self.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer(data_dir, model_path):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    class_mappings_path = os.path.join(WORK_DIR, 'class_mappings.json')\n",
        "    if not os.path.exists(class_mappings_path):\n",
        "        class_mappings_path = 'class_mappings.json'\n",
        "    \n",
        "    with open(class_mappings_path, 'r') as f:\n",
        "        class_mappings = json.load(f)\n",
        "    \n",
        "    idx_to_class = {int(k): v for k, v in class_mappings['idx_to_class'].items()}\n",
        "    num_classes = len(idx_to_class)\n",
        "    \n",
        "    model = SimpsonsCNN(num_classes=num_classes).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    \n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    data_path = Path(data_dir)\n",
        "    image_files = sorted(list(data_path.glob('*.jpg')))\n",
        "    \n",
        "    if len(image_files) == 0:\n",
        "        image_files = sorted(list(data_path.glob('*.png'))) + sorted(list(data_path.glob('*.jpeg')))\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, img_path in enumerate(image_files):\n",
        "            try:\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "                image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "                \n",
        "                outputs = model(image_tensor)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predicted_class_idx = predicted.item()\n",
        "                predicted_class_name = idx_to_class[predicted_class_idx]\n",
        "                \n",
        "                results[img_path.name] = predicted_class_name\n",
        "                \n",
        "                if (idx + 1) % 100 == 0:\n",
        "                    print(f\"Processed {idx + 1}/{len(image_files)} images...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {img_path}: {e}\")\n",
        "                results[img_path.name] = list(idx_to_class.values())[0]\n",
        "    \n",
        "    with open('results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    \n",
        "    print(f\"Predictions completed. Total: {len(results)}\")\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results = infer('test_data_dir', os.path.join(WORK_DIR, 'model.pth'))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
